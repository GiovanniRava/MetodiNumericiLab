


import numpy as np
import matplotlib.pyplot as plt





#La funzione di cui calcolare il condizionamento è f(q)=-p+sqrt{p^2+q},
#al variare di q, con q che tende a zero.
#Si calcola l'indice di condizionamento K=|f'(q)*q/f(q)| 
#si verifica che quando q->0 K ->1. 
#Il problema è ben condizionato. (vedi pdf in allegato)
p=10**5
q=10.0**(-np.arange(11))
x=-p+np.sqrt(p**2 + q)
#La formula risolutiva non è numericamente stabile, perchè  quando q risulta più piccolo dello spacing 
#in p**2, si ha il fenomeno della perdita di cifre significative, ovvero il contributo che da q alla 
#radice non viene calcolato
print("Spacing per p**2: ", np.spacing(p**2), "\nvaloridi q: ",q)
print(x)
#L'instabilità numerica si verifica per valori di q più piccoli dello spacing per 10**5 che è 
# da dato  1.9073486328125e-06 






x=10.0**(-np.arange(21))
f=lambda x: ((1+x)-1)/x
#l'algoritmo può essere instabile perchè con x molto piccoli la somma viene arrotondata: 1+x = 1
#-> (1+x)+1 = 0 -> 0/x è errato--> problema della instabilità numerica per cancellazione
print(x)
print(f(x))
plt.semilogx(x,f(x),x,np.ones_like(x))
#per x >>x**-16 si ottiene un risultato >1 o =1
#per x<<-16 si ottiene f(x)<1 o =0
#il problema quindi è instabile per x piccoli 








import math
n=34
b = np.zeros((n,))
s = np.zeros((n,))
p = np.zeros((n,))
b[0]=2
s[0]=1
print("spacing in [1,2]: ", np.spacing(1)) 
for i in range(1,n):
    p[i]=b[i-1]*s[i-1]
    b[i]=2*b[i-1]
    print(i,s[i-1]**2)
    s[i]=math.sqrt((1.0-math.sqrt(1-s[i-1]**2))/2.0)
#per i grandi s[i]->0, la radice quadrata interna diventa diventa quasi 1 e avviene la cancellazione 
#numerica
#Si verifica che s[i-1]**2 dall'iterato 28 in avanti  assume un valore più piccolo
#dello spacing in [1,2], circa 2.e-16. Questo comporta dall'iterato 30 in avanti
#l' annullamento di s[i]  ed il conseguente annullamento di p[i]
# I problemi di instabilità si cominciano a vedere già prima di questo iterato in quanto s[i-1] tende a diminuire
# e quidni quando si sottrae da 1 un valore via via sempre più piccolo si ha una perdita di cifre significative,
#dovute al fatto che nelle operazioni di somma bisogna prima allineare gli esponenti e quindi scalare le mantisse,
#e questo quando i numeri sono molto piccoli può portare alla cancellazione di cifre significative
plt.title("P[i]")
plt.plot(np.arange(1,n),p[1:n],np.arange(1,n),p[1:n])
err_rel = np.abs(p-math.pi)/math.pi
plt.figure(figsize=(8, 5))
plt.plot(np.arange(len(p)), err_rel, marker='o')
plt.yscale('log')
plt.xlabel("Indice i")
plt.ylabel("Errore relativo (log scale)")
plt.title("Errore relativo per approssimazioni di π")
plt.grid(True)
plt.show()

#nella versione stabile elimino 1-√1-s**2 così da evitare la cancellazione numerica
bs=np.zeros((n,))
ss=np.zeros((n,))
ps=np.zeros((n,))
bs[0]=2
ss[0]=1
for i in range(1,n):
    ps[i]=bs[i-1]*ss[i-1]
    bs[i]=2*bs[i-1]
    print(i,ss[i-1]**2)
    ss[i]=ss[i-1]/math.sqrt((2.0*(1.0+math.sqrt(1.0-ss[i-1]**2))))
plt.title("P[i]")
plt.plot(np.arange(1,n),p[1:n],np.arange(1,n),ps[1:n])

err_rel1 = np.abs(ps-math.pi)/math.pi
plt.figure(figsize=(8, 5))
plt.plot(np.arange(len(p)), err_rel1, marker='o')
plt.yscale('log')
plt.xlabel("Indice i")
plt.ylabel("Errore relativo (log scale)")
plt.title("Errore relativo per approssimazioni di π")
plt.grid(True)
plt.show()





def esp_taylor(x,N):
    r=x#variabile di appoggio che contiene x^n
    fattoriale = 1#variabile per il calcolo del fattoriale 
    esponenziale= 1+r ;#viene iniziallizato ai primi due termini 1+x
    for i in range (2, N+1):
        r=r*x
        fattoriale = fattoriale*i;
        esponentiale = esponenziale+r/fattoriale;
    return esponentiale


N=100
for i in range(-10,10):
    print(i)
    print("Exp con funzione: ", esp_taylor(i,N))
    print("Exp con numpy: ", np.exp(i))
    err_rel= np.abs(esp_taylor(i,N)-np.exp(i))/np.exp(i)
    print("Errore relativo: ", err_rel)

def esp_taylor_stabile(x,N):
    
    if x<0:
        x=abs(x)
        r=x
        fattoriale=1
        esponential=1+r;
        for i in range(2,N+1):
            r=r*x
            fattoriale=fattoriale*i;
            esponential=esponential+r/fattoriale;
    
        return 1/esponential
    
    else: 

        r=x
        fattoriale=1
        esponential=1+r;
        for i in range(2,N+1):
            r=r*x
            fattoriale=fattoriale*i;
            esponential=esponential+r/fattoriale;
        return esponential

N=100
for i in range(-10,10):
    print(i)
    print("Exp con funzione: ", esp_taylor_stabile(i,N))
    print("Exp con numpy: ", np.exp(i))
    err_rel= np.abs(esp_taylor_stabile(i,N)-np.exp(i))/np.exp(i)
    print("Errore relativo: ", err_rel)





x=1
k=np.arange(0,-21.0,-1)
h=10.0**k
des = math.cos(1)
rai = (np.sin(x+h)-np.sin(x))/h
print("Spacing in [1,2]: ", np.spacing(1))
print("Incremento h: ", h)
print("Rai: ", rai)
err_rel=np.abs(rai-des)/np.abs(des)
plt.plot(h,err_rel,'b-',h,h,'r:')
plt.xscale("log")
plt.yscale("log")
plt.legend(['Errore relativo', 'Incremento', 'x=1e-16'])
plt.axvline(x=1e-16, color='gray', linestyle='--', label='x = 1e-16')

#per valori grandi di h(1,0.1,0.01) l'approssimazione è abbastanza lontana dal valore corretto: errori 
#significativi, per h tra 10**-1 e 10**-7 l'approssimazione migliore progresssivamente avvcinandosi a cos(1)
#l'errore relativo diminuisce, per h tra 10**-8 e 10**-16 l'errore raggiunge un minimo vicino alla precisione
#di macchina e poi aumento, per h <10**-16 il risultato diventa 0 o irrilevante con un errore enorme


#Si osserva che quando il valore dell'incremento h, risulta più piccolo dello spacing 
#in [1,2], cioè a partire da h=1e-16, il numeratore si annulla a causa della
#cancellazione di cifre significative, e quindi il rapporto incrementale si 
#annulla.





def valuta_horner(a,x):#a è l'array dei coefficienti del polinomio
    n=a.shape[0]#numero di coefficienti

    p=a[n-1]*np.ones_like(x)#inizialliza p con il termine di grado massimo e lo moltiplica per un array
    #i 1 della stessa forma di x, p può essere aggiornato elememento per elemento
    for i in range(2,n+1):#il ciclo va al contrario da n-1 a 0 e compone il polinomio
         p=p*x+a[n-i] 
    return p

def valuta_alg1(a,x):
    n=a.shape[0]
    p=a[0]*np.ones_like(x)
    r=1
    for i in range(1,n):
        r=r*x
        p=p+a[i]*r
    return p


import time
n=1000000 
x=np.linspace(1.8,2.2,n)
a=np.array([256, -1024, 1792, -1792, 1120, -448, 112, -16 ,1],dtype=float);
start_time=time.perf_counter()
pol1=valuta_alg1(a,x)
stop_time=time.perf_counter()
print("Tempo algoritmo 1 ",stop_time-start_time)
start_time=time.perf_counter()
polh=valuta_horner(a,x)
stop_time=time.perf_counter()
print("Tempo algoritmo horner ",stop_time-start_time)
plt.plot(x,pol1,x,polh,'r')

'''
Si conferma sperimentalmente che lo schema di Horner per
valutare un polinomio in un punto impiega un tempo che è circa la metà di
quello impiegato dall'algoritmo 1.
Il metodo di Horner è piu stabile numericamente e il metodo classico accumula molti errrori di arrotondamento
Horner minimizza cancellazioni numeriche specie se x è vicino a 1
'''





n = 10000













