








import sympy as sym
from sympy import symbols, Matrix, lambdify
import numpy as np
import matplotlib.pyplot as plt


import math
def sign(x):
  """
  Funzione segno che restituisce 1 se x è positivo, 0 se x è zero e -1 se x è negativo.
  """
  return math.copysign(1, x)


def metodo_bisezione(fname, a, b, tolx):
 """
 Implementa il metodo di bisezione per il calcolo degli zeri di un'equazione non lineare.

 Parametri:
  f: La funzione da cui si vuole calcolare lo zero.
  a: L'estremo sinistro dell'intervallo di ricerca.
  b: L'estremo destro dell'intervallo di ricerca.
  tol: La tolleranza di errore.

 Restituisce:
  Lo zero approssimato della funzione, il numero di iterazioni e la lista di valori intermedi.
 """
 fa=fname(a)
 fb=fname(b)
 if sign(fa)*sign(fb)>=0:
     print("Non è possibile applicare il metodo di bisezione \n")
     return None, None,None

 it = 0
 v_xk = []

 
 maxit = math.ceil(math.log2((b - a) / tolx))-1 #Numero massimo di iterazioni necessarie
                                                #per ridurre l'ampiezza dell'intervallo [a,b]
                                                # a dimensione tolx

 while abs(b - a) > tolx:
    xk = a+(b-a)/2
    v_xk.append(xk)
    it += 1
    fxk=fname(xk)
    if fxk==0:
      return xk, it, v_xk

    if sign(fa)*sign(fxk)>0:  #continua su [xk,b]
      a = xk
      fa=fxk
    elif sign(fxk)*sign(fb)>0:   #continua su [a,xk]
      b = xk
      fb=fxk

 
 return xk, it, v_xk



def falsa_posizione(fname,a,b,tolx,tolf,maxit):
    fa=fname(a)
    fb=fname(b)
    if sign(fa*fb)>=0:
       print("Metodo di bisezione non applicabile")
       return None,None,None

    it=0
    v_xk=[]
    fxk=100
    errore=100
    xprec=a
    while it<maxit and abs(fxk)>tolf and errore>tolx:
        xk=a-fa*(b-a)/(fb-fa)
        v_xk.append(xk)
        it+=1
        fxk=fname(xk)
        if fxk==0:
            return xk,it,v_xk

        if sign(fa*fxk)<0:#la radice si trova nell'intervallo [a,xk]
           b=xk
           fb=fxk
        elif sign(fxk*fb)<0: #la radice di trova nell'intervallo [xk,b]
           a=xk
           fa=fxk
        if xk!=0:
            errore=abs(xk-xprec)/abs(xk)
        else:
            errore=abs(xk-xprec)
        xprec=xk
    return xk,it,v_xk


def corde(fname,coeff_ang,x0,tolx,tolf,nmax):
    
     # m è il coefficiente angolare della retta che rimane fisso per tutte le iterazioni
        xk=[]
        
        it=0
        errorex=1+tolx
        erroref=1+tolf
        while it<nmax and  erroref>=tolf and errorex>=tolx :
           
           fx0=fname(x0)
           d=fx0/coeff_ang
           '''
           #x1= ascissa del punto di intersezione tra  la retta che passa per il punto
           (xi,f(xi)) e ha pendenza uguale a coeff_ang  e l'asse x
           '''
           x1=x0-d  
           fx1=fname(x1)
           if x1!=0:
                errorex=abs(d)/abs(x1)
           else:
                errorex=abs(d)
           
           erroref=np.abs(fx1)
           
           x0=x1
           it=it+1
           xk.append(x1)
          
        if it==nmax:
            print('Corde : raggiunto massimo numero di iterazioni \n')
            
        
        return x1,it,xk


def newton(fname,fpname,x0,tolx,tolf,nmax):
  
        xk=[]
       
        it=0
        errorex=1+tolx
        erroref=1+tolf
        while it<nmax and  erroref>=tolf and errorex>=tolx: #abs(d)>=tolx*abs(x1) :
           
           fx0=fname(x0)
           if abs(fpname(x0))<=np.spacing(1): #Se la derivata prima e' pià piccola della precisione di macchina stop
                print(" derivata prima nulla in x0")
                return None, None,None
           d=fx0/fpname(x0)
           '''
           #x1= ascissa del punto di intersezione tra  la retta che passa per il punto
           (xi,f(xi)) ed è tangente alla funzione f(x) nel punto (xi.f(xi))  e l'asse x
           '''
           x1=x0-d  
           fx1=fname(x1)
           erroref=np.abs(fx1)
           if x1!=0:
                errore=abs(d)/abs(x1)
           else:
                errore=abs(d) 

           it=it+1
           x0=x1
           xk.append(x1)
          
        if it==nmax:
            print('Newton: raggiunto massimo numero di iterazioni \n')
            
        
        return x1,it,xk


def secanti(fname,xm1,x0,tolx,tolf,nmax):
        xk=[]
        
        it=0
        errorex=1+tolx
        erroref=1+tolf
        while it<nmax and erroref>=tolf and errorex>=tolx:
            
            fxm1=fname(xm1)
            fx0=fname(x0) 
            d=fx0*(x0-xm1)/(fx0-fxm1)
            #x1 è l'intersezione con l'asse x della retta che passa per l'iterato precedente ed
            # ha coefficiente angolare della retta che passa per i due iterati precedenti
            
            x1=x0-d
          
            
            fx1=fname(x1)
            xk.append(x1);
            if x1!=0:
                errorex=abs(d)/abs(x1)
            else:
                errorex=abs(d)
            erroref=np.abs(fx1)
            xm1=x0
            x0=x1
            
            it=it+1;
           
       
        if it==nmax:
           print('Secanti: raggiunto massimo numero di iterazioni \n')
        
        return x1,it,xk


def stima_ordine(xk,iterazioni):
     #Vedi dispensa allegata per la spiegazione

      k=iterazioni-4
      p=np.log(abs(xk[k+2]-xk[k+3])/abs(xk[k+1]-xk[k+2]))/np.log(abs(xk[k+1]-xk[k+2])/abs(xk[k]-xk[k+1]));
     
      ordine=p
      return ordine


x=sym.symbols('x')
fs =  sym.exp(-x)-(x+1)
dfs=sym.diff(fs,x,1)
titolo='exp(-x)-(x+1)'
fp=lambdify(x,dfs,np)  #l'ultimo argomento np (nickaname di numpy) serve per specificare che la lambda function 
#può prendere come argomento un numpy array ed eseguire l'operazione su tutte le sue componenti.
f=lambdify(x,fs,np)
alfa=0
a = -1
b = 2
x0=-0.5
xm1=-0.3
tolx=1e-14
tolf=1e-14
nmax=100
x1_b,it_b,xk_b=metodo_bisezione(f,a,b,tolx)
print("Ordine Bisezione ",stima_ordine(xk_b,it_b))
x1_f,it_f,xk_f=falsa_posizione(f,a,b,tolx,tolf,nmax)
print("Ordine Falsa posizione ",stima_ordine(xk_f,it_f))

coeff_ang=(f(b)-f(a))/(b-a)
x1_c,it_c,xk_c=corde(f,coeff_ang,x0,tolx,tolf,nmax)
print("Ordine Corde ",stima_ordine(xk_c,it_c))
x1n,it_n,xk_n=newton(f,fp,x0,tolx,tolf,nmax)
print("Ordine Newton ",stima_ordine(xk_n,it_n))
x1_s,it_s,xk_s=secanti(f,xm1,x0,tolx,tolf,nmax)
print("Ordine Secanti ",stima_ordine(xk_s,it_s))
xk_b=np.array(xk_b)
e_b=np.abs(xk_b-alfa)
xk_f=np.array(xk_f)
e_f=np.abs(xk_f-alfa)
xk_c=np.array(xk_c)
e_c=np.abs(xk_c-alfa)
xk_n=np.array(xk_n)
e_n=np.abs(xk_n-alfa)
xk_s=np.array(xk_s)
e_s=np.abs(xk_s-alfa)
plt.semilogy(range(it_b),e_b,'mo-',range(it_f),e_f,'c*-',range(it_c),e_c,'ro-',range(it_n),e_n,'db-',range(it_s),e_s,'gs-')
plt.legend(['Bisezione','Falsa Posizione','Corde','Newton','Secanti'])





f1_s=x**4-9*x**2+4*x+12
df1_s=sym.diff(f1_s,x,1)
print(df1_s.subs(x,-2).evalf())
f1_numerica=lambdify(x,f1_s,np)
df1_numerica=lambdify(x,df1_s,np)
xx=np.linspace(-4,4.0,100)
plt.plot(xx,f1_numerica(xx),xx,np.zeros_like(xx))


#Setting dei parametri per la determinazione della radice 2
x0=3.8
xm1=4.0
alfa=2
x1n,it_n,xk_n=newton(f1_numerica,df1_numerica,x0,tolx,tolf,nmax)
print("Ordine Newton ",stima_ordine(xk_n,it_n))
print('zero Newton ',x1_s,'iterazioni ',it_n)
x1_s,it_s,xk_s=secanti(f1_numerica,xm1,x0,tolx,tolf,nmax)
print('zero secanti ',x1_s,'iterazioni ',it_s)
print("Ordine Secanti ",stima_ordine(xk_s,it_s))
xk_c=np.array(xk_c)
e_c=np.abs(xk_c-alfa)
xk_n=np.array(xk_n)
e_n=np.abs(xk_n-alfa)
xk_s=np.array(xk_s)
e_s=np.abs(xk_s-alfa)
plt.semilogy(range(it_n),e_n,'db-',range(it_s),e_s,'gs-')
plt.legend(['Newton','Secanti'])





def newton_modificato(fname,fpname,m,x0,tolx,tolf,nmax):
  
        #m è la molteplicità dello zero
    
        xk=[]
        it=0
        errorex=1+tolx
        erroref=1+tolf
        while it<nmax and  erroref>=tolf and errorex>=tolx: #abs(d)>=tolx*abs(x1) :
           
           fx0=fname(x0)
           if abs(fpname(x0))<=np.spacing(1): #Se la derivata prima e' pià piccola della precisione di macchina stop
                print(" derivata prima nulla in x0")
                return None, None,None
           d=fx0/fpname(x0)
           '''
           #x1= ascissa del punto di intersezione tra  la retta che passa per il punto
           (xi,f(xi)) ed è tangente alla funzione f(x) nel punto (xi.f(xi))  e l'asse x
           '''
           x1=x0-m*d  
           fx1=fname(x1)
           erroref=np.abs(fx1)
           if x1!=0:
                errore=abs(d)/abs(x1)
           else:
                errore=abs(d) 

           it=it+1
           x0=x1
           xk.append(x1)
          
        if it==nmax:
            print('Newton modificato: raggiunto massimo numero di iterazioni \n')
            
        
        return x1,it,xk


m=2 #è la molteplicità  dello zero cercato
x1n,it_n,xk_n=newton_modificato(f1_numerica,df1_numerica,m,x0,tolx,tolf,nmax)
print("Ordine Newton ",stima_ordine(xk_n,it_n))
print('zero Newton ',x1_s,'iterazioni ',it_n)








import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import sympy as sym


# Definizione variabili simboliche
x_sym, y_sym = symbols('x_sym y_sym')

# Definizione funzioni simboliche usando variabili simboliche 

#f1_sym =lambda x_sym,y_sym: 2*x_sym -sym.cos(y_sym) #[-1,1]
#f2_sym= lambda x_sym,y_sym: sym.sin(x_sym)+2*y_sym


#f1_sym =lambda x_sym,y_sym: x_sym**2 +y_sym**2-4  #[1,2]
#f2_sym= lambda x_sym,y_sym: x_sym**2-y_sym**2-1


#f1_sym = lambda x_sym,y_sym: x_sym**2+y_sym**2-2  #[1,2]
#f2_sym= lambda x_sym,y_sym: sym.exp(x_sym-1)+y_sym**3-3

#f1_sym = lambda x_sym,y_sym: 4*x_sym**2+y_sym**2-4  #[-1,1]
#f2_sym = lambda x_sym,y_sym: x_sym+y_sym-sym.sin(x_sym-y_sym)

       
f1_sym = lambda x_sym,y_sym: x_sym+y_sym-3   #[-1,1]
f2_sym= lambda x_sym,y_sym: x_sym**2+y_sym**2-9



def F_sym(f1_sym,f2_sym):
    return Matrix([[f1_sym(x_sym,y_sym)], [f2_sym(x_sym,y_sym)]])   

# Calcolo della matrice Jacobiana simbolicamente
J_sym = F_sym(f1_sym,f2_sym).jacobian(Matrix([x_sym, y_sym]))

# Converte la matrice jacobiana Simbolica in una funzione che può essere valutata numericamente mediante lambdify
J_numerical = lambdify([x_sym, y_sym], J_sym, np)

# Converte il vettore di funzioni Simbolico in una funzione che può essere valutata numericamente mediante lambdify
F_numerical = lambdify([x_sym, y_sym], F_sym(f1_sym,f2_sym), np)







x = np.arange(-4, 4, 0.1)
y = np.arange(-4, 4, 0.1)
X, Y = np.meshgrid(x, y)
Z=np.zeros_like(X)
superfici=F_numerical(X,Y).squeeze()
 
# Plotta la superficie direttamente
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
# Plotta la superficie
ax.plot_surface(X, Y, superfici[0,:,:], cmap='viridis',alpha=0.5)
# Plotta la superficie
ax.plot_surface(X, Y, superfici[1,:,:], cmap='Reds',alpha=0.5)
ax.plot_surface(X, Y, Z, cmap='gray',alpha=0.5)
plt.contour(X, Y,superfici[0,:,:], levels=[0], colors='black')
plt.contour(X, Y,superfici[1,:,:], levels=[0], colors='red')
 
plt.show()






def newton_raphson(initial_guess, F_numerical, J_Numerical, tolX, tolF, max_iterations):
    

    X= np.array(initial_guess, dtype=float)
    
   

    it=0
    
    erroreF=1+tolF
    erroreX=1+tolX
    
    errore=[]
    
    while it<max_iterations and erroreF>= tolF and erroreX >= tolX:
        
        jx = J_numerical(X[0], X[1]) #la matrice Jacobiana viene aggiornata ad ogni iterato
        
        if np.linalg.det(jx) == 0:
            print("La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo")
            return None, None,None
        
        fx = F_numerical(X[0], X[1])
        fx = fx.squeeze() 
        
        s = np.linalg.solve(jx, -fx)
        
        Xnew=X+s
        # s è Xnew-X;
        normaXnew=np.linalg.norm(Xnew,1)
        if normaXnew !=0:
            erroreX=np.linalg.norm(s,1)/normaXnew
        else:
            erroreX=np.linalg.norm(s,1)
        
        errore.append(erroreX)
        fxnew=F_numerical(Xnew[0], Xnew[1])
        erroreF= np.linalg.norm(fxnew.squeeze(),1)
        X=Xnew
        it=it+1
    
    return X,it,errore


def newton_raphson_corde(initial_guess, F_numerical, J_Numerical, tolX, tolF, max_iterations):
    
    X= np.array(initial_guess, dtype=float)
    
   

    it=0
    
    erroreF=1+tolX
    erroreX=1+tolF
    
    errore=[]
    
    while it<max_iterations and erroreF> tolF and erroreX > tolX:
        
        if it==0:
            jx = J_numerical(X[0], X[1])  #La matrice Jacobiana non viene aggiornata ad ogni iterato
        
            if np.linalg.det(jx) == 0:
                print("La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo")
                return None, None,None
        
        fx = F_numerical(X[0], X[1])
        fx = fx.squeeze() 
        
        s = np.linalg.solve(jx, -fx)
        
        Xnew=X+s
        # s è Xnew-X;
        normaXnew=np.linalg.norm(Xnew,1)
        if normaXnew !=0:
            erroreX=np.linalg.norm(s,1)/normaXnew
        else:
            erroreX=np.linalg.norm(s,1)
            
        errore.append(erroreX)
        fxnew=F_numerical(Xnew[0], Xnew[1])
        erroreF= np.linalg.norm(fxnew.squeeze(),1)
        X=Xnew
        it=it+1
    
    return X,it,errore


def newton_raphson_sham(initial_guess, update, F_numerical, J_Numerical, tolX, tolF, max_iterations):
    
    X= np.array(initial_guess, dtype=float)
    
   

    it=0
    
    erroreF=1+tolX
    erroreX=1+tolF
    
    errore=[]
    
    while it<max_iterations and erroreF> tolF and erroreX > tolX:
        
        if it%update==0:   #Valuto la matrice di iterazione nel nuovo iterato ogni "update" iterazioni
              jx = J_numerical(X[0], X[1])
              
        
              if np.linalg.det(jx) == 0:
                 print("La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo")
                 return None, None,None
        
        fx = F_numerical(X[0], X[1])
        fx = fx.squeeze() 
        
        s = np.linalg.solve(jx, -fx)
        
        Xnew=X+s
        # s è Xnew-X;
        normaXnew=np.linalg.norm(Xnew,1)
        if normaXnew !=0:
            erroreX=np.linalg.norm(s,1)/normaXnew
        else:
            erroreX=np.linalg.norm(s,1)
        errore.append(erroreX)
        fxnew=F_numerical(Xnew[0], Xnew[1])
        erroreF= np.linalg.norm(fxnew.squeeze(),1)
        X=Xnew
        it=it+1
    
    return X,it,errore


initial_guess = [-1,1]
Xs,it,errore = newton_raphson(initial_guess,F_numerical, J_numerical,1e-10,1e-10,100)
print(" Soluzione Newton Raphson ",Xs, "Iterazioni ",it)
Xs_corde,itcorde,errore_corde = newton_raphson_corde(initial_guess,F_numerical, J_numerical,1e-10,1e-10,100)
print(" Soluzione Newton Raphson Corde",Xs_corde, "Iterazioni ",itcorde)
step_update=5
Xs_sham,it_sham,errore_sham = newton_raphson_sham(initial_guess,step_update,F_numerical, J_numerical,1e-10,1e-10,100)
print(" Soluzione Newton Raphson Sham ",Xs_sham, "Iterazioni ",it_sham)


plt.contour(X, Y,superfici[0,:,:], levels=[0], colors='black')
plt.contour(X, Y,superfici[1,:,:], levels=[0], colors='red')
plt.plot(Xs[0],Xs[1],'go')
plt.show()


plt.semilogy(np.arange(it),errore,'ro-',np.arange(itcorde),errore_corde,'gs-',np.arange(it_sham),errore_sham,'ks-')
plt.legend(['Newton Raphson','Corde','Shamanskii'])





x_sym, y_sym = symbols('x_sym y_sym')


F_sym=0.5*(0.001*(x_sym-1)**2+(x_sym**2-y_sym)**2)
#F_sym= (x_sym-2)**4 +(( x_sym-2)**2)*y_sym**2 + (y_sym+1)**2
#F_sym= x_sym**4 +( x_sym+y_sym)**2*y_sym**2 + (sym.exp(x_sym)-1)**2
#F_sym=100*(y_sym-x_sym**2)**2+(1-x_sym)**2
grad_f = sym.derive_by_array(F_sym, (x_sym,y_sym))
print("Gradiente:", grad_f)

# Calcolo dell'Hessiana con sympy.hessian
H = sym.hessian(F_sym, (x_sym,y_sym))
print("Hessiana:", H)

# Conversione delle espressioni simboliche in funzioni numeriche
grad_f_func = sym.lambdify((x_sym,y_sym), grad_f, 'numpy')
H_func = sym.lambdify((x_sym,y_sym), H, 'numpy')
F_func=sym.lambdify((x_sym,y_sym), F_sym, 'numpy')


x = np.arange(-4, 4, 0.1)
y = np.arange(-4, 4, 0.1)
X, Y = np.meshgrid(x, y)
Z=F_func(X,Y)



fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
# Plotta la superficie
ax.plot_surface(X, Y, Z, cmap='viridis',alpha=0.5)




def newton_raphson_minimo(initial_guess, grad_func, Hessian_func, tolX, tolF, max_iterations):
    

    X= np.array(initial_guess, dtype=float)
    
    it=0
    
    erroreF=1+tolX
    erroreX=1+tolF
    
    errore=[]
    
    while it<max_iterations and erroreF>= tolF and erroreX >= tolX:
        
        Hx = Hessian_func(X[0], X[1])
        
        if np.linalg.det(Hx) == 0:
            print("La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo")
            return None, None,None
        
        gfx = grad_func(X[0], X[1])
        gfx = gfx.squeeze() 
        
        s = np.linalg.solve(Hx, -gfx)
        
        Xnew=X+s
        # s è Xnew-X;
        normaXnew=np.linalg.norm(Xnew,1)
        if normaXnew!=0:
            erroreX=np.linalg.norm(s,1)/normaXnew
        else:
            erroreX=np.linalg.norm(s,1)
            
        errore.append(erroreX)
        #Calcolo il gradiente in Xnew
        gfxnew=grad_func(Xnew[0], Xnew[1])
        #il criterio di arresto sarà fatto sulla norma del gradiente, perchè il nostro obiettivo è tgrovare un punto critico,
        #cioè un punto che annulla il gradiente
        erroreF= np.linalg.norm(gfxnew.squeeze(),1)
        X=Xnew
        it=it+1
    
    return X,it,errore


initial_guess = [-3.0,-3.0]
Xs_min,it,errore = newton_raphson_minimo(initial_guess,grad_f_func, H_func,1e-10,1e-10,100)
print(" Newton Raphson in ",Xs_min, "Iterazioni ",it)






valH=H_func(Xs_min[0],Xs_min[1])
print(valH)


print(np.linalg.det(valH))


fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
# Plotta la superficie
ax.plot_surface(X, Y, Z, cmap='viridis',alpha=0.5)
plt.plot(Xs_min[0],Xs_min[1],'ro')









