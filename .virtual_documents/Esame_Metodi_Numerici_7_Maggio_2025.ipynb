


#nel caso di matrici quadrate diremo che una matrice è piccola qunado la sua 50<dim<100, per dire che è grande 300<dim<500.
#la sparsità si codnisdera se la matrice è grande. Se la matrice è nxn, il coefficiente di sparsità sp = #nonzeros/nxn, se sp<33% è sparsa altrimenti è densa
#Se la matrice è siimmetrica e def pos Jacobi non è detto che converga, quinid usiamo Gauss Seidel(SOR, per aumentare la velocità), Gradiente, Gradiente coniugato
#Per capire se una matrica è def pos allora possiamo usare o 1) il criterio di Silvester--> dove vengono calcolati tutti i minori principali hanno tutti determinati 
#maggiori di zero

#Se la matrice A è piccola dobbiamo ricorrere ai metodi di fattorizzazione, Gauss, Cholesky, QR. se la matrice(piccola, densa) è simmetrica e def pos allora possiamo 
#fattorizzarla con CHolesky, A=L*L^T. Si riduce a risolvere due sistemi, LL^Tx=b --> Ly=b L^Tx=b. Capire come usarle, qunado ma non sono da implementare. Se A è molto 
#mal condizionato meglio usare algoritmi più stabili. Gauss è stabili in senso debole, CHolesky è piu stabile(stabile in senso forte) rispetto a Gauss, fattorizzazione QR è il piu stabile. 
#Se è ben condizionata la matirce usiamo Gauss anche se non è molto stabile.

#Se la matrice è sovradeterminata (m<n), se ha è ben condizionata e ha rango massimo , la soluzione è A^TAx=A^Tb. se A ha rango massimo e medimaente mal condizionata
#usiamo la fattorizzazione QR. A non è a rango massimo allora A= U(sommmatoria)U^T.
#Indice COndizionamento(K)--> ben condizionata =10^(1,2), mediamente condizionata = 10^(3,4), mal condizionata=10^(5,...). C'è il metodo cond di linalg
#K(A) = ||A||*||A^-1||








from scipy.io import loadmat

import numpy as np
import matplotlib.pyplot as plt

dati = loadmat('test_7_maggio_2025')

A=dati["A"] 

A=A.astype(float)

b=dati["b"]

b=b.astype(float)

A1=dati["A1"] 

A1=A1.astype(float)

b1=dati["b1"]

b1=b1.astype(float)


m,n=A.shape
print("Dimensioni matrice A", m , n)
sp=np.count_nonzero(A)/(m*n)
print("percentuale di sparsità", sp)


plt.spy(A)


#Verifichiamo se la matrice è simmmetrice 
flagS= A==A.T
if np.all(flagS==True):
    print("Matrice simmentrica")
else: 
    print("Matrice non simmentrica")


#Definita positiva
eigenvalue=np.linalg.eigvals(A)
if np.all(eigenvalue)>0 :
    print("matrice def pos")
else:
    print("mantrice non def pos")


#indice di condizionamento
condA=np.linalg.cond(A)
print(condA)


def steepestdescent(A,b,x0,itmax,tol):
 
    n,m=A.shape
    if n!=m:
        print("Matrice non quadrata")
        return [],[]
    
    
   # inizializzare le variabili necessarie
    x = x0

     
    r =A@x-b  
    p =-r 
    it = 0
    nb=np.linalg.norm(b)
    errore=np.linalg.norm(r)/nb
    vec_sol=[]
    vec_sol.append(x.copy())
    vet_r=[]
    vet_r.append(errore)
     
# utilizzare il metodo del gradiente per trovare la soluzione
    while errore>=tol and it<itmax : 
        it=it+1
        Ap=A@p
       
        alpha = -(r.T@p)/(p.T@Ap)                
        x = x+alpha*p
         
        vec_sol.append(x.copy())
        r=r+alpha*Ap
        errore=np.linalg.norm(r)/nb
        vet_r.append(errore)
        p =-r#to do 
        
    iterates_array = np.vstack([arr.T for arr in vec_sol])
    return x,vet_r,iterates_array,it


x0=np.zeros_like(b) #cosa molto importante da non sbagliare 
tol=1e-6
itmax=2000
x,vet_r,iterates_array,it = steepestdescent(A,b,x0,itmax,tol)
print("IT ", it)
print(x.shape) 
#print ("X= ", x)

plt.semilogy(range(len(vet_r)), vet_r)


#indice di condizionamento A1
condA1=np.linalg.cond(A1)
print(condA1)


x01=np.zeros_like(b1) #cosa molto importante da non sbagliare 
tol=1e-6
itmax=2000
x1,vet_r1,iterates_array1,it1 = steepestdescent(A1,b1,x01,itmax,tol)
print("IT ", it1)
print(x1.shape) 
#print ("X= ", x)

plt.semilogy(range(len(vet_r1)), vet_r1)


def conjugate_gradient(A,b,x0,itmax,tol):
    n,m=A.shape
    if n!=m:
        print("Matrice non quadrata")
        return [],[]
    
    
   # inizializzare le variabili necessarie
    x = x0
    
    r = A@x-b#to do 
    p = -r
    it = 0
    nb=np.linalg.norm(b)
    errore=np.linalg.norm(r)/nb
    vec_sol=[]
    vec_sol.append(x0.copy())
    vet_r=[]
    vet_r.append(errore)
# utilizzare il metodo del gradiente coniugato per calcolare la soluzione
    while errore>=tol and it<itmax:
        it=it+1
        Ap=A@p#to do A.dot(p)
        alpha = -(r.T@p)/(p.T@Ap)
        x =x+alpha*p #to do 
        vec_sol.append(x.copy())
        rtr_old=r.T@r#to do
        r= r+alpha*Ap#to do 
        gamma= r.T@r/rtr_old 
        errore=np.linalg.norm(r)/nb
        vet_r.append(errore)
        p = r+gamma*p#to do 
   
    iterates_array = np.vstack([arr.T for arr in vec_sol])
    return x,vet_r,iterates_array,it


def gauss_seidel(A,b,x0,toll,it_max):
    errore=1000
    d=np.diag(A)#to do 
    D=np.diag(d)#to do 
    E=np.tril(A,-1)#to do 
    F=np.tril(A,1)#to do 
    M=D+E#to do 
    N=-F#to do 
    T=np.linalg(M)@N#to do 
    autovalori=np.linalg.eigvals(T)
    raggiospettrale=np.max(np.abs(autovalori))#to do 
    print("raggio spettrale Gauss-Seidel ",raggiospettrale)
    it=0
    er_vet=[]
    while it<itmax and errore>=toll :#to do 
        x=Lsolve(M,b-F@x0)#to do 
        errore=np.lingal.normk(x-x0)/np.linalg.norm(x)#to do 
        er_vet.append(errore)
        x0=x.copy()
        it=it+1
    return x,it,er_vet


x0=np.zeros_like(b) #cosa molto importante da non sbagliare 
tol=1e-6
itmax=2000
xCG,vet_rCG,iterates_arrayCG,itCG = conjugate_gradient(A,b,x0,itmax,tol)
print("IT ", itCG)
print(x.shape) 
#print ("X= ", x)

plt.semilogy(range(len(vet_rCG)), vet_rCG)


## Esercizio  2

**Siano assegnati i punti del piano di coordinate $(x_i, y_i)$, $i=1,\ldots,3$ con**
$$
\begin{array}{c}
x_1=1, \quad x_2=4, \quad x_3=0, \\
y_1=1, \quad y_2=0, \quad y_3=4 .
\end{array}
$$ 
Scrivere lo script Python  in cui
- si costruisce il sistema lineare  ottenuto imponendo il passaggio della circonferenza di equazione $x^2+y^2+a_1x+a_2y+a_3=0$ per i tre punti assegnati, e si denotino con ${\bf M}$ e ${\bf b}$ la matrice dei coefficienti e il termine noto ottenuti;   [**punti 3**]

- si calcola la soluzione del sistema lineare ${\bf M}{\bf a}={\bf b}$ usando il metodo di fattorizzazione adatto alle caratteristiche della matrice $M$[**punti 2**]

- dopo averne determinato centro e raggio (vedi sotto formula), si rappresentino in una stessa figura la circonferenza di equazione $x^2+y^2+a_1x+a_2y+a_3=0$ (dove i coefficienti $a_i$ rappresentano la soluzione del sistema lineare del punto precedente) e i tre punti assegnati dal problema.[**punti 1**]
- Abbiamo costruito la circonferenza  ................... i punti del piano
  [**punti 1**] 
  (completare al posto dei puntini)






import numpy as np 
import scipy as sp
from SolveTriangular import *
import math
import matplotlib.pyplot as plt
M=np.array([[1,1,1],[4,0,1],[0,4,1]])
b=np.array([[-2],[-16],[-16]])


condM=np.linalg.cond(M)
print("indice di condizionamento ", condM)
#fattorizzazione LU
PT,L,U=sp.linalg.lu(M)
t,flag =Lsolve(L,PT.T@b)
a,flag=Usolve(U,t)


cx=-a[0]/2
cy=-a[1]/2
r1=math.sqrt((a[0]**2)/4+(a[1]**2)/4-a[2])
t=np.linspace(0,2*np.pi,100)
x=cx+r1*np.cos(t)
y=cy+r1*np.sin(t)
plt.plot(x,y,'r-')





A =np.array([[1,1,1],[4,0,1],[0,4,1], [5.0,6,1]])
c1=np.array([[-1],[-16],[-16],[-61.0]])
pxi=np.array([1,2,0,5.0])
pyi=np.array([1,0,4,6.0])
print(A)


def qrLS(A,b):
    n=A.shape[1]  # numero di colonne di A
    Q,R=sp.linalg.qr(A)
    h=Q.T@b#to do 
    x,flag=Usolve(R[0:n,0:n],h[0:n])#to do
    residuo=np.linalg.norm(h[n:])#to do 
    return x,residuo


a1,residuo=qrLS(A,c1)
print("residuo " , residuo)
cx1=-a[0]/2
cy1=-a[1]/2
r1=math.sqrt((a[0]**2)/4+(a[1]**2)/4-a[2])
t=np.linspace(0,2*np.pi,100)
x=cx1+r1*np.cos(t)
y=cy1+r1*np.sin(t)
plt.plot(x,y,'r-')






























