





from scipy.io import loadmat
import numpy as np
import matplotlib.pyplot as plt
from SolveTriangular import *
import scipy as sp
dati = loadmat('testI')
A=dati["A"] 
A=A.astype(float)
b=dati["b"]
b=b.astype(float)


n,m = A.shape
if m==n:
    print("matrice quadrata, dim:", m)
else:
    print("matrice non quadrata")
print("COndizionamento di A: ", np.linalg.cond(A))


sp=np.count_nonzero(A)/(m*n)
print("Sparsità: ", sp)
plt.spy(A)


flagS= A==A.T
if np.all(flagS==True):
    print("matrice simmetrica")
else: 
    print("matrice non simmetrica")


def is_strictly_diagonally_dominant(A):
    for i in range(A.shape[0]):
        diag = abs(A[i, i])
        off_diag_sum = np.sum(np.abs(A[i, :])) - diag
        if diag <= off_diag_sum:
            return False
    return True

# Uso:
if is_strictly_diagonally_dominant(A):
    print("La matrice è diagonalmente strettamente dominante")
else:
    print("La matrice NON è diagonalmente strettamente dominante")



def jacobi(A,b,x0,toll,it_max):
    errore=1000
    d=np.diag(A)
    n=A.shape[0]
    invM=np.diag(1/d)
    E=np.tril(A, 1)
    F=np.triu(A,-1)
    N=-(E+F)
    T=invM@N 
    autovalori=np.linalg.eigvals(T)
    raggiospettrale=np.max(np.abs(autovalori)) 
    print("raggio spettrale jacobi", raggiospettrale)
    it=0
    
    er_vet=[]
    while it<=it_max and errore>=toll:
        x=(b+N@x0)/d.reshap(n,1)
        errore=np.linalg.norm(x-x0)/np.linalg.norm(x)
        er_vet.append(errore)
        x0=x.copy()
        it=it+1
    return x,it,er_vet


def gauss_seidel(A,b,x0,toll,it_max):
    errore=1000
    d=np.diag(A)
    D=np.diag(d)
    E=np.tril(A,-1)
    F=np.triu(A,1)
    M=D+E
    N=-F
    T=np.linalg.inv(M)@N 
    autovalori=np.linalg.eigvals(T)
    raggiospettrale=np.max(np.abs(autovalori))
    print("raggio spettrale Gauss-Seidel ",raggiospettrale)
    it=0
    er_vet=[]
    while it<=it_max and errore >=toll:
        x,flag=Lsolve(M, b-F@x0)
        errore=np.linalg.norm(x-x0)/np.linalg.norm(x)
        er_vet.append(errore)
        x0=x.copy()
        it=it+1
    return x,it,er_vet

def gauss_seidel_sor(A,b,x0,toll,it_max,omega):
    errore=1000
    d=np.diag(d)
    D=np.diag(A) 
    E=np.tril(A,-1) 
    F=np.triu(A,1)
    Momega=D+omega*E
    Nomega=(1-omega)*D-omega*F
    T=np.linalg.inv(Momega)@Nomega
    autovalori=np.linalg.eigvals(T)
    raggiospettrale= np.max(np.abs(autovalori))
    print("raggio spettrale Gauss-Seidel SOR ", raggiospettrale)
    
    M=D+E
    N=-F
    it=0
    xold=x0.copy()
    xnew=x0.copy()
    er_vet=[]
    while it<=it_max and errore>=toll:
        
        xtilde,flag=Lsolve(M, b-F@xold) 
        xnew=(1-omega)*xold+omega*xtilde
        errore=np.linalg.norm(xnew-xold)/np.linalg.norm(xnew)
        er_vet.append(errore)
        xold=xnew.copy()
        it=it+1
    return xnew,it,er_vet







def LUSolve(P, A, L, U, b):
    pb=np.dot(P,b)
    y,flag=Lsolve(L, pb)
    if flag == 0:
        x, flag=Usolve(U,y)
    else:
        return [],flag
    return x, flag


A2=np.array([[3.0,2.0,2.0,-1.0],[4.0,6.0,3.0,2.0], [2.0,2.0,4.0,3.0],[1.0,4.0,2.0,7.0]])
b2=np.sum(A2, axis=1).reshape(A2.shape[0], 1)
PT,L,U = sp.linalg.lu(A2)
P=PT.T.copy()
x,flag=LUSolve(P,A2,L,U,b2)
print("X: ", x)


detA2=np.linalg.det(PT)*np.prod(np.diag(U))#deriva dal fatto che PA=LU e PT è la matrice di permutazione
print("determinate calcolato con LU: ", detA2)
print("determinante con np.det: ", np.linalg.det(A2))


n = A2.shape[0]
I = np.eye(n)
inv_A2 = np.zeros_like(A2)

for i in range(n):
    e = I[:, i].reshape(-1, 1)  # colonna dell'identità
    x, flag = LUSolve(P, A2, L, U, e)
    inv_A2[:, i] = x.flatten()  # salva la colonna trovata

print("Inversa calcolata via LU:\n", inv_A2)
print("Inversa con numpy.linalg.inv:\n", np.linalg.inv(A2))






def newton_raphson(initial_guess, F_numerical, J_Numerical, tolX, tolF, max_iterations):

    X= np.array(initial_guess, dtype=float)
    it=0
    
    erroreF=1+tolF
    erroreX=1+tolX
    
    errore=[]
    
    while it<= max_iterations and erroreX>= tolX and erroreF>= tolF:
        jx = J_Numerical(X[0], X[1])
        
        if np.linalg.det(jx)==0:
            print("La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo")
            return None, None,None
        
        fx = F_numerical(X[0],X[1])
        fx = fx.squeeze() 
        
        s = np.linalg.solve(jx, -fx)
        
        Xnew=X+s
        
        normaXnew=np.linalg.norm(Xnew,1)
        if normaXnew !=0:
            erroreX=np.linalg.norm(Xnew-x)/normaXnew
        else:
            erroreX=np.linalg.norm(Xnew-X)
        
        errore.append(erroreX)
        fxnew=F_numerical(Xnew[0], Xnew[1])
        erroreF= np.linalg.norm(fxnew.squeeze(),1)
        X=Xnew
        it=it+1
    
    return X,it,errore



def newton_raphson_corde(initial_guess, F_numerical, J_Numerical, tolX, tolF, max_iterations):
    

    X= np.array(initial_guess, dtype=float)
    it=0
    erroreF=1+tolF
    erroreX=1+tolX
    
    errore=[]
    
    while it<=max_iterations and erroreF >=tolF and erroreX>=tolX:
        
        if it==0:
            jx = J_Numerical(X[0],X[1])
        
            if np.linalg.det(jx)==0:
                print("La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo")
                return None, None,None
        
        fx = F_numerical(X[0],X[1])
        fx = fx.squeeze() 
        
        s = np.linalg.solve(jx,-fx)
        
        Xnew=X+s
        
        normaXnew=np.linalg.norm(Xnew,1)
        if normaXnew !=0:
            erroreX=np.linalg.norm(s)/normaXnew
        else:
            erroreX=np.linalg.norm(s)
        
        errore.append(erroreX)
        fxnew=F_numerical(Xnew[0], Xnew[1])
        erroreF= np.linalg.norm(fxnew.squeeze(),1)
        X=Xnew
        it=it+1
    
    return X,it,errore




def newton_raphson_sham(initial_guess, update, F_numerical, J_Numerical, tolX, tolF, max_iterations):
    
    X= np.array(initial_guess, dtype=float)
    it=0
    erroreF=1+tolF
    erroreX=1+tolX
    
    errore=[]
    
    while it<=max_iterations and erroreF>=tolF and erroreX>=tolX:
        if it%update==0:
            jx = J_Numerical(X[0],X[1])
        
            if np.linalg.det(jx)==0:
                print("La matrice dello Jacobiano calcolata nell'iterato precedente non è a rango massimo")
                return None, None,None
        
        fx = F_numerical(X[0],X[1])
        fx = fx.squeeze() 
        
        s = np.linalg.solve(jx,-fx) 
        
        Xnew=X+s
        
        normaXnew=np.linalg.norm(Xnew,1)
        if normaXnew !=0:
            erroreX=np.linalg.norm(s)/normaXnew
        else:
            erroreX=np.linalg.norm(s)/normaXnew
        
        errore.append(erroreX)
        fxnew=F_numerical(Xnew[0],Xnew[1])
        erroreF= np.linalg.norm(fxnew.squeeze(),1)
        X=Xnew
        it=it+1

    return X,it,errore





import matplotlib.pyplot as plt
def F_numerical(x0,x1):
    return np.array([
        x0*x1+x0-1,
        x0**2+x1**2-9
    ]).reshape(2,1)
def J_numerical(x0,x1):
    return np.array([
        [x1+1,x0],
        [2*x0,2*x1]
    ])

initial_guess=[1.0,1.0]
tolX=1e-8
tolF=1e-8
max_iterations=100
XNR,itNR,erroreNR =newton_raphson(initial_guess, F_numerical, J_numerical, tolX, tolF, max_iterations)
plt.semilogy(np.arange(len(erroreNR)), erroreNR, 'r-')
print("X: ", XNR)
print("IT:", itNR)





initial_guess=[1.0,1.0]
tolX=1e-8
tolF=1e-8
max_iterations=100
X_corde,it_corde,errore_corde=newton_raphson_corde(initial_guess, F_numerical, J_numerical, tolX, tolF, max_iterations)
plt.semilogy(np.arange(len(errore_corde)), errore_corde, 'r-')
print("X: ", X_corde)
print("IT: ", it_corde)


initial_guess=[1.0,1.0]
tolX=1e-8
tolF=1e-8
max_iterations=100
update=3
X_Sham,it_sham,errore_sham =newton_raphson_sham(initial_guess,update, F_numerical, J_numerical, tolX, tolF, max_iterations)
plt.semilogy(np.arange(len(errore_sham)), errore_sham, 'r-')
print("X: ", X_Sham)
print("IT: ", it_sham)


plt.semilogy(np.arange(len(errore_sham)), errore_sham, 'r-',np.arange(len(errore_corde)), errore_corde, 'b-', np.arange(len(erroreNR)), erroreNR, 'g-')


def f1(x0, x1):
    return x0 * x1 + x0 - 1

def f2(x0, x1):
    return x0**2 + x1**2 - 9

x0_vals = np.linspace(-4, 4, 400)
x1_vals = np.linspace(-4, 4, 400)
X0, X1 = np.meshgrid(x0_vals, x1_vals)

Z1 = f1(X0, X1)
Z2 = f2(X0, X1)

plt.contour(X0, X1, Z1, levels=[0], colors='red', label='f1=0')
plt.contour(X0, X1, Z2, levels=[0], colors='blue', label='f2=0')
plt.xlabel("x0")
plt.ylabel("x1")
plt.title("Intersezione curve di livello")
plt.grid(True)
plt.show()






































